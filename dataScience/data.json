{"posts":[{"file":"06_03_2023-Neuroevolution.md","date":"06/03/2023","title":"# Neuroevolution","content":"<p>Last week I looked into neuroevolution in machine learning and theory behind how it works and how it can be used in preperation for the exam. Although I have looked into a lot of information behind how it works, I don't have enough time or space to go through all that I have studied, so I will leave a link to the notes I have take for it <a href=\"./references/Neuroevolution_Notes.pdf\">here</a>. I will however go through the basics of what it is and how it works.</p>\n<h2 id=\"whatisneuroevolution\">What is Neuroevolution?</h2>\n<p>To put it simply, neuroevolution is a machine learning technique used to generate increasingly better topologies, weights &amp; hyperparameters (Parameter whose value is used to control the learning process) for a neural network (NN) by means of evolutionary algorithms (such as a genetic algorithm). One of the most simple ways of describing it, is if you had a neural network and genetic algorithm and combined the two, then you'd have neuroevolution.</p>\n<p>As we know, neural networks deal with a set amount of nodes and connections which have weights and biases to affect each output and input into the next nodes which will then affect the output data, allowing for a decision to be made, which simulates the way a brain would make decisions with set neurons (without developing any new neurons or connections, but instead modifying the bias and weight of each neuron).</p>\n<p>Neuroevolution takes it a step further and will add in new neurons, modify weights, add new connections and remove connections, all of which will be done with the ideas from the genetic algorithm. This allows for the neural network to be able to adapt to new situations and environments and become more and more complex in its NN as time goes on.</p>\n<h2 id=\"howdoesitwork\">How does it work?</h2>\n<p>Neuroevolution works by using a genetic algorithm to evolve the neural network. The genetic algorithm will use a population of genes mapped to a neural network, which will then be evaluated on how well in did in the specific environment and given a score based on that. The genes will then be sorted by their score and the best genes will be selected to be the parents of the next generation. The parents will then be crossed over and mutated to create the next generation of genes, which will share the positive traits of the parents, but also have some new traits which will allow for the NN to adapt and test new traits. This process will continue until the NN is able to complete the task at hand.</p>\n<h2 id=\"howisitused\">How is it used?</h2>\n<p>Neuroevolution is used in a lot of different ways, for example in self driving cars, where the NN will be trained to drive a car in different circumstances, usually in a simulation in Unreal Engine or something similar. The NN will then learn on the go, figuring out what to and what not to do, and will be able to adapt to the new situations it is put in. This is a very useful technique, as it allows for the NN to be able to become smarter with each generation and develop a better understanding of how to attack a problem put in front of it. The reason it's put into a simulation is because it's a lot easier to test and train the NN. If you were to put it into a real car, you would have to be very careful as to make sure it doesn't damage itself (as that would be expensive) or anyone else, as this could be dangerous.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>As stated, this is a very simple breakdown of the neuroevolution techniques, there are a lot more situations it can be applied to and a lot more information behind how it works, but as stated, there isn't enough time and space to go through all of it here, and so in future when I work on it more, there will be more information to how it works and it's applications, but if you would like to read through a really brief set of notes that are unstructured and not very well written, but contain a decent bit of information on how it works, then you can find them <a href=\"./references/Neuroevolution_Notes.pdf\">here</a>. Last week was quite interesting, I loved diving into how all of the different machine learning techniques work and how they can be used, and I'm looking forward to learning more about them in the future. This was a topic that I'd been looking forward to for a few years, but I didn't have the background knowledge required to get an in-depth understanding of it before hand, so I'm glad I've finally been able to learn about it and understand it. I've spent a lot of time on it, as can be seen in the notes, and I have been able to really use the time well to get a firm understanding, but next week I'm going to take a step back into the Monte Carlo technique and keep going from there. As usual, I'll keep you updated on how it goes.</p>","preview":"<p>Last week I looked into neuroevolution in machine learning and theory behind how it works and how it can be used in preperation for the exam. Although I have looked into a lot of information behind how it works, I don't have enough time or space to go through all that I have studied, so I will leave a link to the notes I have take for it <a href=\"./references/Neuroevolution_Notes.pdf\">here</a>. I will however go through the basics of what it is and how it works.</p>\n<h2 id=\"whatisneuroevol","id":"Neuroevolution"},{"file":"27_02_2023-MonteCarloAI.md","date":"27/02/2023","title":"# The Monte Carlo AI Method","content":"<h2 id=\"whatisthemontecarlomethod\">What is the Monte Carlo Method?</h2>\n<p>To put it simply: The Monte Carlo method is a probability based AI that makes decisions off of a bunch of random variations of a situation to calculate the likelihood of a specific decision being the correct one in its context.</p>\n<h2 id=\"howdoesitwork\">How does it work?</h2>\n<p>To explain how it works, I'll use an example: Let's say you were playing a game of Tic Tac Toe, if you were to play a move anywhere on the board whilst versing an AI based off the Monte Carlo method, it would play a bunch of random variations of the game in the background, and scoring each of those games based on the outcome, and then it would play the move that would have the highest score or likelihood of contributing to a win.</p>\n<p>To give a better explanation of the scoring that would happen, let's visualise it:</p>\n<table>\n    <tr>\n        <th>X</th>\n        <th>O</th>\n        <th>X</th>\n    </tr>\n    <tr>\n        <th>X</th>\n        <th>O</th>\n        <th>O</th>\n    </tr>\n    <tr>\n        <th>X</th>\n        <th></th>\n        <th></th>\n    </tr>\n</table>\n<h3 id=\"scoring\">Scoring</h3>\n<p>In this example, lets say the player is X and the AI is O, it would play a bunch of games in the background, and score each of them. To score them it would take a board like this one and assign values to each move that it has played, for instance if the AI won the game, it would assign a value of 1 to each move that it played, and a value of -1 to each move that the player played. If the player won, it would assign a value of 1 to each move that the player played and a value of 1 to each move that the AI played. In this scenario the scoring of the board would look like this:</p>\n<table>\n    <tr>\n        <th>1</th>\n        <th>-1</th>\n        <th>1</th>\n    </tr>\n    <tr>\n        <th>1</th>\n        <th>-1</th>\n        <th>-1</th>\n    </tr>\n    <tr>\n        <th>1</th>\n        <th>0</th>\n        <th>0</th>\n    </tr>\n</table>\n<p>From this, the AI would take the highest scoring move and place it's move there. This would, in theory, give the AI the best chance of winning.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Although the Monte Carlo AI is very simple, it is quite effective at a lot of different things, such as playing games, and even making decisions for other scenaries. I haven't implemented it myself yet, but will be looking into that next time I get the chance, as I will be researching into AI and Machine Learning this week and next week I have exams, so I will be continuing the implementation of the Monte Carlo AI after that, or possibly next week if I get the chance.</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>I hope that was a good explanation of the Monte Carlo AI, as I have spent the last week working well on going through how it works and the theory behind it. I have spent the time looking through lectures and reading the usages of the AI and continuing to collaborate with classmates about the different topics that we learn in class. Over the next few weeks I will be doing a few things, those being:</p>\n<ol>\n<li><p>Researching Neural Networks, their history and how they work (exam prep, this week)</p></li>\n<li><p>Doing exams (next week)</p></li>\n<li><p>Implementing the Monte Carlo AI (after exams)</p></li>\n</ol>\n<p>That should cover everything I've covered so far, and I will continue posting updates on my progress each week.</p>","preview":"<h2 id=\"whatisthemontecarlomethod\">What is the Monte Carlo Method?</h2>\n<p>To put it simply: The Monte Carlo method is a probability based AI that makes decisions off of a bunch of random variations of a situation to calculate the likelihood of a specific decision being the correct one in its context.</p>\n<h2 id=\"howdoesitwork\">How does it work?</h2>\n<p>To explain how it works, I'll use an example: Let's say you were playing a game of Tic Tac Toe, if you were to play a move anywhere on the bo","id":"MonteCarloAI"},{"file":"20_02_2023-TheBigOThetaAndOmega.md","date":"20/02/2023","title":"# The Big O, Θ & Ω","content":"<p>So, last week we covered the Big O and how to calculate the Big O as well as it's uses. This week we're going to look at the Big Ω and Big Θ as well as it was meant to be covered but I had accidentally moved past the two and went to the work from the next week, so I looked at it this week.</p>\n<h2 id=\"thebigorecap\">The Big O Recap</h2>\n<p>The Big O is a way of calculating the upper bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's worst case scenario and is used as a way of comparing algorithms to each other. A definition of the Big O from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = O(g(n)) if there exists c &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≤ c * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>This is just the formula, to say that anywhere after a specific value of n, or x, the function f(n), which is the algorithm's real runtime, will be less than or equal to the function g(n) multiplied by a constant c (which will produce the Big O value). This will be the upper bound for the runtime of the algorithm.</p>\n<h2 id=\"thebig\">The Big Ω</h2>\n<p>The Big Ω is the opposite of the Big O, it's the lower bound for the runtime of an algorithm. It's measures the efficiency of an algorithm in it's best case scenario and is also used as a way of comparing algorithms to each other. A definition of the Big Ω from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = Ω(g(n)) if there exists c &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≥ c * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>Which if you spotted it, is just saying the same as the Big O, but instead of being less than or equal to, it's greater than or equal to, thus this will always produce a value less than or equal to the real runtime, indicating the best case scenario. This will be the lower bound for the runtime of the algorithm.</p>\n<h2 id=\"thebig-1\">The Big Θ</h2>\n<p>The Big Θ is the combination of the Big O and Big Ω, it's the exact bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's average case scenario and is also used as a way of comparing algorithms to each other. A definition of the Big Θ from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = Θ(g(n)) if there exists c<sub>1</sub> &gt; 0, c<sub>2</sub> &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≤ c<sub>1</sub> * g(n) for all n ≥ n<sub>0</sub> and f(n) ≥ c<sub>2</sub> * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>Which is just saying that the function f(n) will be less than or equal to the function g(n) multiplied by a constant c<sub>1</sub> (Big O/Upper Bound) and greater than or equal to the function g(n) multiplied by a constant c<sub>2</sub> (Big Ω/Lower Bound). This will be the upper and lower constraints of the algorithm's runtime.</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>The last week was very math heavy, looking back over the Big O, Ω &amp; Θ and realising the actual mathematical formulae behind them, it's very interesting to see how they work and how they're used but it also encourages you to check the running time of different algorithms to get a good idea of which are best to use for different situations.</p>","preview":"<p>So, last week we covered the Big O and how to calculate the Big O as well as it's uses. This week we're going to look at the Big Ω and Big Θ as well as it was meant to be covered but I had accidentally moved past the two and went to the work from the next week, so I looked at it this week.</p>\n<h2 id=\"thebigorecap\">The Big O Recap</h2>\n<p>The Big O is a way of calculating the upper bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's worst case scenario","id":"TheBigOThetaAndOmega"},{"file":"13_02_2023-TheBigO.md","date":"13/02/2023","title":"# The Big O","content":"<h2 id=\"whatisthebigo\">What is the Big O?</h2>\n<p>Big O notation is a way to describe the performance of an algorithm as the input size increases. It takes into account the upper bound of an algorithms run time, viewing the worst case scenario and is frequently used to compare the performance of different algorithms. The Big O is usually used whilst looking at large amounts of data, as smaller input sizes matter much less when running these algorithms.</p>\n<h2 id=\"whyisitimportant\">Why is it important?</h2>\n<p>Big O notation is used to compare run times and performance of different algorithms in worst case scenarios, when using a lot of data, it's useful to know which algorithms to use for doing certain functions</p>\n<h2 id=\"howcanyoucalculatethebigoforanalgorithm\">How can you calculate the Big O for an algorithm?</h2>\n<p>To calculate the Big O for an algorithm, you need to understand how many operations would be performed for a specific input size, then you can start calculating the amount of operations that would be performed on a larger data set. The calculation from there is simple, first you will need to do the following using some simple maths:</p>\n<ol>\n<li>Find the highest power of n in the equation<ul>\n<li>If you have an equation, 3n^4 + 500n + 2, the term 3n^4 has n^4, the highest power of n</li></ul></li>\n<li>Remove the coefficient from the term<ul>\n<li>From 3n^4 we would get n^4</li></ul></li>\n</ol>\n<h2 id=\"dominantterms\">Dominant Terms</h2>\n<p>The remaining term, n^4 is the dominant term of the algorithm as it has the highest power of n. To understand this, we could look at the 3n^4 next to 500n. Although some think that 500n will be larger, they'd be wrong, or at least when n&gt;5, as before that, 500n would be bigger. Due to the fact that n will be in a large subset of data when used, with &gt;500,000 data points, the n^4 will have the greatest effect on the algorithm's run time (the coefficient will provide a small change but not much).</p>\n<h2 id=\"calculatingthebigocont\">Calculating the Big O (cont.)</h2>\n<p>In the following table, you can see that there are two things you have to look at when looking into the run time of algorithms, the input size (on the left) and the number of operations to be performed for those sizes (log(n) onwards), although these input sizes are still quite small you can already start to see a big difference in the run times. Even when the input size is still small, and they seem quite similar, as soon as you start looking into the bigger input sizes, the run times can differ significantly.</p>\n<table>\n<tr>\n<th>Input Size</th>\n<th>log(n)</th>\n<th>n</th>\n<th>n^2</th>\n<th>2^n</th>\n</tr>\n<tr>\n<th>2</th>\n<th>1</th>\n<th>2</th>\n<th>4</th>\n<th>4</th>\n</tr>\n<tr>\n<th>16</th>\n<th>4</th>\n<th>16</th>\n<th>256</th>\n<th>65536</th>\n</tr>\n<tr>\n<th>256</th>\n<th>8</th>\n<th>256</th>\n<th>65536</th>\n<th>1.1579*10^77</th>\n</tr>\n</table>\n<p>Therefore when comparing the run times of different algorithms, you need to look into how the run time increases as the input size increases towards infinity, thus we would need to look at the dominating terms, ignoring any lower order terms.</p>\n<h2 id=\"mergesortdivideconquer\">Merge Sort/Divide &amp; Conquer</h2>\n<p>Let's say you have a list of numbers to sort in order of their size, and it looks like this:</p>\n<p><code>[ 7, 20, 5, 4, 8, 13, 100, 11 ]</code></p>\n<p>To sort this you wouldn't go through and compare each number other number, as for each term you would have to compare it to every other term. e.g. 7 would be compared with 20, 5, 4, 8, 13, 100, 11 taking 7 operations. If you were continuedthis for each term, the total operations would be n*(n-1) or n^2-n giving O(n^2). This is an very inefficient way of sorting a list of numbers, and there are better ways to do this, one of which is the merge sort algorithm:</p>\n<ol>\n<li><p>Divide the problem into sub-problems</p></li>\n<li><p>Solve each sub-problem recursively</p></li>\n<li><p>Merge the solutions of each sub problem until the original problem is solved</p></li>\n</ol>\n<p>For example, if you have that same list of numbers to sort you would:</p>\n<ol>\n<li><p>Split the list into two halves</p>\n<ul>\n<li>Recursively split the sub lists into two halves until you have 1 term in each list</li></ul></li>\n<li><p>Sort the sub lists and merge them together recursively</p></li>\n</ol>\n<h2 id=\"mergesortexample\">Merge Sort Example</h2>\n<p>e.g.\n    step 1:</p>\n<pre><code>`[ 7, 20, 5, 4, 8, 13, 100, 11 ]`\n\n`[ 7, 20, 5, 4 ]` + `[ 8, 13, 100, 11 ]`\n\n`[ 7, 20 ]` + `[ 5, 4 ]` + `[ 8, 13 ]` + `[ 100, 11 ]`\n\n`[ 7 ]` + `[ 20 ]` + `[ 5 ]` + `[ 4 ]` + `[ 8 ]` + `[ 13 ]` + `[ 100 ]` + `[ 11 ]`\n\nstep 2:\n\n`[ 7 ]` + `[ 20 ]` + `[ 5 ]` + `[ 4 ]` + `[ 8 ]` + `[ 13 ]` + `[ 100 ]` + `[ 11 ]`\n\n`[ 7, 20 ]` + `[ 4, 5 ]` + `[ 8, 13 ]` + `[ 11, 100 ]`\n\n`[ 4, 5, 7, 20 ]` + `[ 8, 11, 13, 100 ]`\n\n`[ 4, 5, 7, 8, 11, 13, 20, 100 ]`\n</code></pre>\n<h2 id=\"mergesortalgorithm\">Merge Sort Algorithm</h2>\n<p>An algorithm for step 2 could look like:</p>\n<p>Take the second merge step for example, you would have your two sorted sub-lists [ 7, 20 ] and [ 4, 5 ], to merge these, name 3 variables, <code>A</code>, <code>B</code>, and <code>C</code>, where <code>A</code> and <code>B</code> are the sub-lists and <code>C</code> is the merged list, which is empty at this point. You would then have <code>i</code>, <code>j</code>, and <code>k</code> as indexes for each list. The merge algorithm would work as follows:</p>\n<ol>\n<li><p>Set <code>i = 0</code>, <code>j = 0</code>, and <code>k = 0</code></p></li>\n<li><p>If <code>A[i] &gt; B[j]</code>, set <code>C[k]</code> to <code>A[i]</code> and increment <code>i</code> and <code>k</code>, if <code>B[j] was greater</code> you would increment <code>j</code> and <code>k</code> instead</p></li>\n<li><p>Repeat until C is full</p></li>\n</ol>\n<p>(You would do the same on the first merge, but it would be more simple)</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>As you can see, over the past week I have taken a lot of time to look into the Big O and taken that little bit of extra time to make sure that I have understood it enough to explain it in this post. I have used my time in class efficiently to get this done, but also taken time outside of class to make sure that I have gotten an in-depth understanding of what I have learnt so far, and I will use it in the future to continue understanding more about the Big O and algorithms for when I start to look into ML. Over the next few weeks I will continue to look into the Big O and different algorithms and <em>maybe</em> ML. Either way, a blog post will come out each week.</p>","preview":"<h2 id=\"whatisthebigo\">What is the Big O?</h2>\n<p>Big O notation is a way to describe the performance of an algorithm as the input size increases. It takes into account the upper bound of an algorithms run time, viewing the worst case scenario and is frequently used to compare the performance of different algorithms. The Big O is usually used whilst looking at large amounts of data, as smaller input sizes matter much less when running these algorithms.</p>\n<h2 id=\"whyisitimportant\">Why is it ","id":"TheBigO"}]}