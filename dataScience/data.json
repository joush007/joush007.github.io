{"posts":[{"file":"27_02_2023-MonteCarloAI.md","date":"27/02/2023","title":"# The Monte Carlo AI Method","content":"<h2 id=\"whatisthemontecarlomethod\">What is the Monte Carlo Method?</h2>\n<p>To put it simply: The Monte Carlo method is a probability based AI that makes decisions off of a bunch of random variations of a situation to calculate the likelihood of a specific decision being the correct one in its context.</p>\n<h2 id=\"howdoesitwork\">How does it work?</h2>\n<p>To explain how it works, I'll use an example: Let's say you were playing a game of Tic Tac Toe, if you were to play a move anywhere on the board whilst versing an AI based off the Monte Carlo method, it would play a bunch of random variations of the game in the background, and scoring each of those games based on the outcome, and then it would play the move that would have the highest score or likelihood of contributing to a win.</p>\n<p>To give a better explanation of the scoring that would happen, let's visualise it:</p>\n<table>\n    <tr>\n        <th>X</th>\n        <th>O</th>\n        <th>X</th>\n    </tr>\n    <tr>\n        <th>X</th>\n        <th>O</th>\n        <th>O</th>\n    </tr>\n    <tr>\n        <th>X</th>\n        <th></th>\n        <th></th>\n    </tr>\n</table>\n<h3 id=\"scoring\">Scoring</h3>\n<p>In this example, lets say the player is X and the AI is O, it would play a bunch of games in the background, and score each of them. To score them it would take a board like this one and assign values to each move that it has played, for instance if the AI won the game, it would assign a value of 1 to each move that it played, and a value of -1 to each move that the player played. If the player won, it would assign a value of 1 to each move that the player played and a value of 1 to each move that the AI played. In this scenario the scoring of the board would look like this:</p>\n<table>\n    <tr>\n        <th>1</th>\n        <th>-1</th>\n        <th>1</th>\n    </tr>\n    <tr>\n        <th>1</th>\n        <th>-1</th>\n        <th>-1</th>\n    </tr>\n    <tr>\n        <th>1</th>\n        <th>0</th>\n        <th>0</th>\n    </tr>\n</table>\n<p>From this, the AI would take the highest scoring move and place it's move there. This would, in theory, give the AI the best chance of winning.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Although the Monte Carlo AI is very simple, it is quite effective at a lot of different things, such as playing games, and even making decisions for other scenaries. I haven't implemented it myself yet, but will be looking into that next time I get the chance, as I will be researching into AI and Machine Learning this week and next week I have exams, so I will be continuing the implementation of the Monte Carlo AI after that, or possibly next week if I get the chance.</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>I hope that was a good explanation of the Monte Carlo AI, as I have spent the last week working well on going through how it works and the theory behind it. I have spent the time looking through lectures and reading the usages of the AI and continuing to collaborate with classmates about the different topics that we learn in class. Over the next few weeks I will be doing a few things, those being:</p>\n<ol>\n<li><p>Researching Neural Networks, their history and how they work (exam prep, this week)</p></li>\n<li><p>Doing exams (next week)</p></li>\n<li><p>Implementing the Monte Carlo AI (after exams)</p></li>\n</ol>\n<p>That should cover everything I've covered so far, and I will continue posting updates on my progress each week.</p>","preview":"<h2 id=\"whatisthemontecarlomethod\">What is the Monte Carlo Method?</h2>\n<p>To put it simply: The Monte Carlo method is a probability based AI that makes decisions off of a bunch of random variations of a situation to calculate the likelihood of a specific decision being the correct one in its context.</p>\n<h2 id=\"howdoesitwork\">How does it work?</h2>\n<p>To explain how it works, I'll use an example: Let's say you were playing a game of Tic Tac Toe, if you were to play a move anywhere on the bo","id":"MonteCarloAI"},{"file":"20_02_2023-TheBigOThetaAndOmega.md","date":"20/02/2023","title":"# The Big O, Θ & Ω","content":"<p>So, last week we covered the Big O and how to calculate the Big O as well as it's uses. This week we're going to look at the Big Ω and Big Θ as well as it was meant to be covered but I had accidentally moved past the two and went to the work from the next week, so I looked at it this week.</p>\n<h2 id=\"thebigorecap\">The Big O Recap</h2>\n<p>The Big O is a way of calculating the upper bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's worst case scenario and is used as a way of comparing algorithms to each other. A definition of the Big O from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = O(g(n)) if there exists c &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≤ c * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>This is just the formula, to say that anywhere after a specific value of n, or x, the function f(n), which is the algorithm's real runtime, will be less than or equal to the function g(n) multiplied by a constant c (which will produce the Big O value). This will be the upper bound for the runtime of the algorithm.</p>\n<h2 id=\"thebig\">The Big Ω</h2>\n<p>The Big Ω is the opposite of the Big O, it's the lower bound for the runtime of an algorithm. It's measures the efficiency of an algorithm in it's best case scenario and is also used as a way of comparing algorithms to each other. A definition of the Big Ω from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = Ω(g(n)) if there exists c &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≥ c * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>Which if you spotted it, is just saying the same as the Big O, but instead of being less than or equal to, it's greater than or equal to, thus this will always produce a value less than or equal to the real runtime, indicating the best case scenario. This will be the lower bound for the runtime of the algorithm.</p>\n<h2 id=\"thebig-1\">The Big Θ</h2>\n<p>The Big Θ is the combination of the Big O and Big Ω, it's the exact bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's average case scenario and is also used as a way of comparing algorithms to each other. A definition of the Big Θ from a function (f(n)) is:</p>\n<blockquote>\n  <p>f(n) = Θ(g(n)) if there exists c<sub>1</sub> &gt; 0, c<sub>2</sub> &gt; 0, n<sub>0</sub> ≥ 0 such that f(n) ≤ c<sub>1</sub> * g(n) for all n ≥ n<sub>0</sub> and f(n) ≥ c<sub>2</sub> * g(n) for all n ≥ n<sub>0</sub></p>\n</blockquote>\n<p>Which is just saying that the function f(n) will be less than or equal to the function g(n) multiplied by a constant c<sub>1</sub> (Big O/Upper Bound) and greater than or equal to the function g(n) multiplied by a constant c<sub>2</sub> (Big Ω/Lower Bound). This will be the upper and lower constraints of the algorithm's runtime.</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>The last week was very math heavy, looking back over the Big O, Ω &amp; Θ and realising the actual mathematical formulae behind them, it's very interesting to see how they work and how they're used but it also encourages you to check the running time of different algorithms to get a good idea of which are best to use for different situations.</p>","preview":"<p>So, last week we covered the Big O and how to calculate the Big O as well as it's uses. This week we're going to look at the Big Ω and Big Θ as well as it was meant to be covered but I had accidentally moved past the two and went to the work from the next week, so I looked at it this week.</p>\n<h2 id=\"thebigorecap\">The Big O Recap</h2>\n<p>The Big O is a way of calculating the upper bound for the runtime of an algorithm. It measures the efficiency of an algorithm in it's worst case scenario","id":"TheBigOThetaAndOmega"},{"file":"13_02_2023-TheBigO.md","date":"13/02/2023","title":"# The Big O","content":"<h2 id=\"whatisthebigo\">What is the Big O?</h2>\n<p>Big O notation is a way to describe the performance of an algorithm as the input size increases. It takes into account the upper bound of an algorithms run time, viewing the worst case scenario and is frequently used to compare the performance of different algorithms. The Big O is usually used whilst looking at large amounts of data, as smaller input sizes matter much less when running these algorithms.</p>\n<h2 id=\"whyisitimportant\">Why is it important?</h2>\n<p>Big O notation is used to compare run times and performance of different algorithms in worst case scenarios, when using a lot of data, it's useful to know which algorithms to use for doing certain functions</p>\n<h2 id=\"howcanyoucalculatethebigoforanalgorithm\">How can you calculate the Big O for an algorithm?</h2>\n<p>To calculate the Big O for an algorithm, you need to understand how many operations would be performed for a specific input size, then you can start calculating the amount of operations that would be performed on a larger data set. The calculation from there is simple, first you will need to do the following using some simple maths:</p>\n<ol>\n<li>Find the highest power of n in the equation<ul>\n<li>If you have an equation, 3n^4 + 500n + 2, the term 3n^4 has n^4, the highest power of n</li></ul></li>\n<li>Remove the coefficient from the term<ul>\n<li>From 3n^4 we would get n^4</li></ul></li>\n</ol>\n<h2 id=\"dominantterms\">Dominant Terms</h2>\n<p>The remaining term, n^4 is the dominant term of the algorithm as it has the highest power of n. To understand this, we could look at the 3n^4 next to 500n. Although some think that 500n will be larger, they'd be wrong, or at least when n&gt;5, as before that, 500n would be bigger. Due to the fact that n will be in a large subset of data when used, with &gt;500,000 data points, the n^4 will have the greatest effect on the algorithm's run time (the coefficient will provide a small change but not much).</p>\n<h2 id=\"calculatingthebigocont\">Calculating the Big O (cont.)</h2>\n<p>In the following table, you can see that there are two things you have to look at when looking into the run time of algorithms, the input size (on the left) and the number of operations to be performed for those sizes (log(n) onwards), although these input sizes are still quite small you can already start to see a big difference in the run times. Even when the input size is still small, and they seem quite similar, as soon as you start looking into the bigger input sizes, the run times can differ significantly.</p>\n<table>\n<tr>\n<th>Input Size</th>\n<th>log(n)</th>\n<th>n</th>\n<th>n^2</th>\n<th>2^n</th>\n</tr>\n<tr>\n<th>2</th>\n<th>1</th>\n<th>2</th>\n<th>4</th>\n<th>4</th>\n</tr>\n<tr>\n<th>16</th>\n<th>4</th>\n<th>16</th>\n<th>256</th>\n<th>65536</th>\n</tr>\n<tr>\n<th>256</th>\n<th>8</th>\n<th>256</th>\n<th>65536</th>\n<th>1.1579*10^77</th>\n</tr>\n</table>\n<p>Therefore when comparing the run times of different algorithms, you need to look into how the run time increases as the input size increases towards infinity, thus we would need to look at the dominating terms, ignoring any lower order terms.</p>\n<h2 id=\"mergesortdivideconquer\">Merge Sort/Divide &amp; Conquer</h2>\n<p>Let's say you have a list of numbers to sort in order of their size, and it looks like this:</p>\n<p><code>[ 7, 20, 5, 4, 8, 13, 100, 11 ]</code></p>\n<p>To sort this you wouldn't go through and compare each number other number, as for each term you would have to compare it to every other term. e.g. 7 would be compared with 20, 5, 4, 8, 13, 100, 11 taking 7 operations. If you were continuedthis for each term, the total operations would be n*(n-1) or n^2-n giving O(n^2). This is an very inefficient way of sorting a list of numbers, and there are better ways to do this, one of which is the merge sort algorithm:</p>\n<ol>\n<li><p>Divide the problem into sub-problems</p></li>\n<li><p>Solve each sub-problem recursively</p></li>\n<li><p>Merge the solutions of each sub problem until the original problem is solved</p></li>\n</ol>\n<p>For example, if you have that same list of numbers to sort you would:</p>\n<ol>\n<li><p>Split the list into two halves</p>\n<ul>\n<li>Recursively split the sub lists into two halves until you have 1 term in each list</li></ul></li>\n<li><p>Sort the sub lists and merge them together recursively</p></li>\n</ol>\n<h2 id=\"mergesortexample\">Merge Sort Example</h2>\n<p>e.g.\n    step 1:</p>\n<pre><code>`[ 7, 20, 5, 4, 8, 13, 100, 11 ]`\n\n`[ 7, 20, 5, 4 ]` + `[ 8, 13, 100, 11 ]`\n\n`[ 7, 20 ]` + `[ 5, 4 ]` + `[ 8, 13 ]` + `[ 100, 11 ]`\n\n`[ 7 ]` + `[ 20 ]` + `[ 5 ]` + `[ 4 ]` + `[ 8 ]` + `[ 13 ]` + `[ 100 ]` + `[ 11 ]`\n\nstep 2:\n\n`[ 7 ]` + `[ 20 ]` + `[ 5 ]` + `[ 4 ]` + `[ 8 ]` + `[ 13 ]` + `[ 100 ]` + `[ 11 ]`\n\n`[ 7, 20 ]` + `[ 4, 5 ]` + `[ 8, 13 ]` + `[ 11, 100 ]`\n\n`[ 4, 5, 7, 20 ]` + `[ 8, 11, 13, 100 ]`\n\n`[ 4, 5, 7, 8, 11, 13, 20, 100 ]`\n</code></pre>\n<h2 id=\"mergesortalgorithm\">Merge Sort Algorithm</h2>\n<p>An algorithm for step 2 could look like:</p>\n<p>Take the second merge step for example, you would have your two sorted sub-lists [ 7, 20 ] and [ 4, 5 ], to merge these, name 3 variables, <code>A</code>, <code>B</code>, and <code>C</code>, where <code>A</code> and <code>B</code> are the sub-lists and <code>C</code> is the merged list, which is empty at this point. You would then have <code>i</code>, <code>j</code>, and <code>k</code> as indexes for each list. The merge algorithm would work as follows:</p>\n<ol>\n<li><p>Set <code>i = 0</code>, <code>j = 0</code>, and <code>k = 0</code></p></li>\n<li><p>If <code>A[i] &gt; B[j]</code>, set <code>C[k]</code> to <code>A[i]</code> and increment <code>i</code> and <code>k</code>, if <code>B[j] was greater</code> you would increment <code>j</code> and <code>k</code> instead</p></li>\n<li><p>Repeat until C is full</p></li>\n</ol>\n<p>(You would do the same on the first merge, but it would be more simple)</p>\n<h2 id=\"reflection\">Reflection</h2>\n<p>As you can see, over the past week I have taken a lot of time to look into the Big O and taken that little bit of extra time to make sure that I have understood it enough to explain it in this post. I have used my time in class efficiently to get this done, but also taken time outside of class to make sure that I have gotten an in-depth understanding of what I have learnt so far, and I will use it in the future to continue understanding more about the Big O and algorithms for when I start to look into ML. Over the next few weeks I will continue to look into the Big O and different algorithms and <em>maybe</em> ML. Either way, a blog post will come out each week.</p>","preview":"<h2 id=\"whatisthebigo\">What is the Big O?</h2>\n<p>Big O notation is a way to describe the performance of an algorithm as the input size increases. It takes into account the upper bound of an algorithms run time, viewing the worst case scenario and is frequently used to compare the performance of different algorithms. The Big O is usually used whilst looking at large amounts of data, as smaller input sizes matter much less when running these algorithms.</p>\n<h2 id=\"whyisitimportant\">Why is it ","id":"TheBigO"}]}